# Apache Spark Documentation

- Navigate to https://spark.apache.org/ >> **Documentation** >> **Latest Release**
- **API Docs** >> **Python** >> **API Reference**

- Spark API is categorized in eight packages:
  1. [Spark SQL](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html)
  2. Pandas API on Spark
  3. Structured Streaming
  4. MLlib
  5. Spark Streaming
  6. Spark Core
  7. Resource Management

## 01. PySpark SQL Packages

https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html
- We have the following PySpark SQL core classes:
* [pyspark.sql.SparkSession](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)
* pyspark.sql.Catalog
* [pyspark.sql.DataFrame](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html)
* pyspark.sql.Column
* pyspark.sql.Observation
* pyspark.sql.Row
* pyspark.sql.GroupedData
* pyspark.sql.PandasCogroupedOps
* pyspark.sql.DataFrameNaFunctions
* pyspark.sql.DataFrameStatFunctions
* pyspark.sql.Window
* pyspark.sql.DataFrameReader
* pyspark.sql.DataFrameWriter
* pyspark.sql.DataFrameWriterV2
* pyspark.sql.UDFRegistration
* pyspark.sql.UDTFRegistration
* pyspark.sql.udf.UserDefinedFunction
* pyspark.sql.udtf.UserDefinedTableFunction

## 02. 